<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel><title>Instructor (JS)</title><description>Enhancing OpenAI function calling with Zod</description><link>https://instructor-ai.github.io/instructor-js/</link><atom:link href="https://instructor-ai.github.io/instructor-js/feed_rss_created.xml" rel="self" type="application/rss+xml" /><managingEditor>Jason Liu</managingEditor><docs>https://github.com/instructor-ai/instructor-js</docs><language>en</language> <pubDate>Tue, 05 Mar 2024 20:37:36 -0000</pubDate> <lastBuildDate>Tue, 05 Mar 2024 20:37:36 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.12.1</generator> <item> <title>Structured Outputs with Together and Zod</title> <author>jxnl</author> <category>open source</category> <category>patching</category> <description>&lt;h1&gt;Structured Outputs with Together and Zod&lt;/h1&gt;&lt;p&gt;Open-source LLMS are gaining popularity, and the release of Togethers&#39;s Mistral model has made it possible to obtain structured outputs using JSON schema. Instead of relying on a model&#39;s default output mode, you can utilize JSON schema to obtain structured outputs. This approach is a time-saving alternative to extensive prompt engineering.&lt;/p&gt;&lt;p&gt;By the end of this blog post, you will learn how to effectively utilize instructor with Togethers. But before we proceed, let&#39;s first explore the concept of patching.&lt;/p&gt;</description><link>https://instructor-ai.github.io/instructor-js/blog/2024/02/01/together/</link> <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate><source url="https://instructor-ai.github.io/instructor-js/feed_rss_created.xml">Instructor (JS)</source><guid isPermaLink="true">https://instructor-ai.github.io/instructor-js/blog/2024/02/01/together/</guid> <enclosure url="https://instructor-ai.github.io/instructor-js/assets/images/social/blog/posts/together.png" type="image/png" length="48395" /> </item> <item> <title>Structured Outputs with Anyscale and Zod</title> <author>jxnl</author> <category>open source</category> <category>patching</category> <description>&lt;h1&gt;Structured Outputs with Anyscale and Zod&lt;/h1&gt;&lt;p&gt;Open-source LLMS are gaining popularity, and the release of Anyscale&#39;s Mistral model has made it possible to obtain structured outputs using JSON schema at any scale. Instead of relying on a model&#39;s default output mode, you can utilize JSON schema to obtain structured outputs. This approach is a time-saving alternative to extensive prompt engineering.&lt;/p&gt;&lt;p&gt;By the end of this blog post, you will learn how to effectively utilize instructor with Anyscale. But before we proceed, let&#39;s first explore the concept of patching.&lt;/p&gt;</description><link>https://instructor-ai.github.io/instructor-js/blog/2024/01/01/anyscale/</link> <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><source url="https://instructor-ai.github.io/instructor-js/feed_rss_created.xml">Instructor (JS)</source><guid isPermaLink="true">https://instructor-ai.github.io/instructor-js/blog/2024/01/01/anyscale/</guid> <enclosure url="https://instructor-ai.github.io/instructor-js/assets/images/social/blog/posts/anyscale.png" type="image/png" length="50404" /> </item> </channel></rss>